{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from TinyImageNet import TinyImageNet\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_images_horizontally\n",
    "from NaiveResNet import NaiveResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟\n",
    "- 讀取資料集\n",
    "- 簡單 EDA\n",
    "    - facets\n",
    "- 定義目標 / loss function\n",
    "- 定義模型\n",
    "- 訓練模型\n",
    "- 測試模型\n",
    "- 視覺化 kernels / parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前處理資料\n",
    "- 讀取資料\n",
    "- 轉換（灰階處理、Augmentation、Crop）\n",
    "\n",
    "注意在 validation 時我們不需要做 augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output of torchvision datasets are PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1].\n",
    "# normalize 在現在有 batch-normalization 的情況下其實非必要\n",
    "normalize = transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "\n",
    "augmentation = transforms.RandomApply([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(64)], p=.8)\n",
    "\n",
    "training_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "    augmentation,\n",
    "    transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "    transforms.ToTensor(),\n",
    "    normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將圖片全讀到記憶體，最小化硬碟 overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_memory = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "training_set = TinyImageNet(root, 'train', transform=training_transform, in_memory=in_memory)\n",
    "valid_set = TinyImageNet(root, 'val', transform=valid_transform, in_memory=in_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 顯示處理後圖片\n",
    "主要是顯示經過 data augmentation 的圖片。為了讓模型更 robust，我們隨機進行水平翻轉、剪裁以及旋轉的處理。在這邊顯示的圖有進行反正規化（un-normalization）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpiter = iter(DataLoader(training_set, batch_size=10, shuffle=True))\n",
    "for _ in range(5):\n",
    "    images, labels = tmpiter.next()\n",
    "    show_images_horizontally(images, un_normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義 loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = NaiveResNet(num_classes=200)\n",
    "device = torch.device(\"cuda\")\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將模型圖寫到 Tensorboard 以供確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "sw = SummaryWriter(log_dir='./runs', comment='NaiveResNet')\n",
    "dummy_input = Variable(torch.rand(16, 3, 64, 64)).to(device)\n",
    "sw.add_graph(resnet, (dummy_input, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = resnet.forward(dummy_input)\n",
    "# out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義 Optimizer, Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(training_set, batch_size=32, shuffle=True, num_workers=4)\n",
    "validloader = DataLoader(valid_set, batch_size=64, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "assert torch.cuda.is_available()\n",
    "try:\n",
    "    for epoch in range(max_epochs):\n",
    "        start = time.time()\n",
    "        lr_scheduler.step()\n",
    "        epoch_loss = 0.0\n",
    "        resnet.train()\n",
    "        for idx, (data, target) in enumerate(trainloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = resnet(data)\n",
    "            batch_loss = ce_loss(output, target)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += batch_loss.item()\n",
    "        \n",
    "            if idx % 10 == 0:\n",
    "                print('{:.1f}% of epoch'.format(idx / float(len(trainloader)) * 100), end='\\r')\n",
    "            \n",
    "            \n",
    "        # evaluate on validation set\n",
    "        num_hits = 0\n",
    "        num_instances = len(valid_set)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            resnet.eval()\n",
    "            for idx, (data, target) in enumerate(validloader):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = resnet(data)\n",
    "                _, pred = torch.max(output, 1) # output.topk(1) *1 = top1\n",
    "\n",
    "                num_hits += (pred == target).sum().item()\n",
    "#                 print('{:.1f}% of validation'.format(idx / float(len(validloader)) * 100), end='\\r')\n",
    "\n",
    "        valid_acc = num_hits / num_instances * 100\n",
    "        print(f' Validation acc: {valid_acc}%')\n",
    "        sw.add_scalar('Validation Accuracy(%)', valid_acc, epoch)\n",
    "            \n",
    "        epoch_loss /= float(len(trainloader))\n",
    "#         print(\"Time used in one epoch: {:.1f}\".format(time.time() - start))\n",
    "        \n",
    "        # save model\n",
    "        torch.save(resnet.state_dict(), 'models/weight.pth')\n",
    "        \n",
    "        # record loss\n",
    "        sw.add_scalar('Running Loss', epoch_loss, epoch)\n",
    "        \n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted. Releasing resources...\")\n",
    "    \n",
    "finally:\n",
    "    # this is only required for old GPU\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd models/;ls -alth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = torch.load('models/weight.pth', map_location=lambda storage, location: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo\n",
    "- Tensorboard\n",
    "- save model by best metrics\n",
    "- 多點augmentation\n",
    "- 要不要加learning rate schduler\n",
    "    - https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
